{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f601f3",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "For Colab, the helper folders need to be copied over from the repo. The below cell does this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb2f61",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Check if the environment variable exists\n",
    "if [ -n \"$COLAB_RELEASE_TAG\" ] || [ -n \"$COLAB_GPU\" ]; then\n",
    "    echo \"Running on Google Colab. Cloning repository into temp folder...\"\n",
    "    git clone https://github.com/TuebingenAICenter/agent-tutorial.git /tmp/tmp_repo\n",
    "    echo \"Moving all helpers to project root...\"\n",
    "    mv /tmp/tmp_repo/chat_with_X_utils .\n",
    "    mv /tmp/tmp_repo/images .\n",
    "    mv /tmp/tmp_repo/env.example ./.env\n",
    "    mv /tmp/tmp_repo/requirements.txt .\n",
    "else\n",
    "    echo \"Not running on Google Colab. Skipping git clone.\"\n",
    "fi\n",
    "\n",
    "# The installation block runs regardless of environment.\n",
    "echo \"Checking for requirements.txt and installing required packages...\"\n",
    "\n",
    "# Check if requirements.txt exists in the current directory\n",
    "if [ -f \"requirements.txt\" ]; then\n",
    "    # Attempt to install with 'uv', and if it fails (exit code != 0), use 'pip' as a fallback.\n",
    "    if command -v uv &> /dev/null; then\n",
    "        echo \"uv detected. Installing with uv...\"\n",
    "        uv pip install -r requirements.txt\n",
    "    else\n",
    "        echo \"Installing with pip...\"\n",
    "        pip install -r requirements.txt\n",
    "    fi\n",
    "else\n",
    "    echo \"ERROR! requirements.txt not found! Please check for errors...\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2bd50",
   "metadata": {},
   "source": [
    "### Setting API key\n",
    "The following cell sets the API key for accessing LLMs. The prompt will ask for `OPENROUTER_API_KEY` if it has not been set in the .env file.\n",
    "\n",
    "Optionally an OpenAI key can be set in the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cced317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Load environment variables from a .env file if it exists\n",
    "dotenv.load_dotenv()\n",
    "  \n",
    "# Prompt for the API key if it's not already set\n",
    "if not os.getenv(\"OPENROUTER_API_KEY\"):\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = getpass(\n",
    "        \"Enter your OPENROUTER API key: \"\n",
    "    )\n",
    "            \n",
    "if not os.environ[\"OPENROUTER_API_KEY\"]:\n",
    "    print(\"WARNING: API key not set. Please run this cell again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90481e",
   "metadata": {},
   "source": [
    "# Example 02: RAG-based YouTube/PDF Chat\n",
    "\n",
    "Now we know how a basic LangGraph system is implemented. Let's upgrade our tools towards a more useful application that let's us chat with an LLM about any PDF document or YouTube video.\n",
    "\n",
    "**What:** chatbot using more complex tools, some of which will require human oversight to use.\n",
    "\n",
    "**Why:** cement advanced concepts via implementation\n",
    "\n",
    "**Live:** this is the notebook called `..._scaffolded.ipynb` that has some crucial lines of code missing. Follow along and see if you can fill in those lines to get the example working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd09ed",
   "metadata": {},
   "source": [
    "## What we plan to create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e9682",
   "metadata": {},
   "source": [
    "<img src=\"./images/Agent_02_diagram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed7452",
   "metadata": {},
   "source": [
    "## What it looks like in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce67a4",
   "metadata": {},
   "source": [
    "<img src=\"./images/Agent_02_conditional_edges_colored_in.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d5bb9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23984ad",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3dd4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "from typing import TypedDict, Annotated, List, Dict, Optional, Literal\n",
    "from datetime import datetime\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import ToolNode, tools_condition, InjectedState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, AIMessage, SystemMessage, BaseMessage, ToolMessage,\n",
    ")\n",
    "\n",
    "# Local utils (explicit imports)\n",
    "from chat_with_X_utils.metadata_mangement import load_metadata\n",
    "from chat_with_X_utils.tool_utils import (\n",
    "    get_documents,\n",
    "    embed_documents,\n",
    "    parse_retrieval,\n",
    "    create_selection_summary,\n",
    "    get_database_info,\n",
    ")\n",
    "from chat_with_X_utils.print_utils import (\n",
    "    print_messages_from_stream_event as _print_messages_from_stream_event,\n",
    "    print_messages_from_state as _print_messages_from_state,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809f0d9",
   "metadata": {},
   "source": [
    "### Vector DB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "EMBEDDINGS_MODEL = \"text-embedding-3-small\"\n",
    "VECTOR_DB_PATH = \"./chroma_db\"\n",
    "METADATA_FILE = \"./document_metadata.json\"\n",
    "\n",
    "# Initialize components (single LLM)\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini-2025-04-14\",\n",
    "        temperature=0.0,\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    )\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=EMBEDDINGS_MODEL, \n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    )\n",
    "else:\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini-2025-04-14\",\n",
    "        temperature=0.0,\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    )\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    # Use a local model for embeddings \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Initialize or load vector store\n",
    "vector_store = Chroma(\n",
    "    persist_directory=VECTOR_DB_PATH,\n",
    "    collection_name=\"rag_documents\",\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74037c88",
   "metadata": {},
   "source": [
    "## Chat with PDFs and YouTube videos (How to use tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63437e",
   "metadata": {},
   "source": [
    "The following cells contain some missing code for you to complete. Places where you need to fill in the missing code are marked by comments like:\n",
    "\n",
    "```# TODO: Do XYZ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3575b4",
   "metadata": {},
   "source": [
    "### [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)\n",
    "\n",
    "Remember that the State ( an instance of `TypedDict`) is the main object that all nodes operate on & communicate with. In our current design, that state is defined to have the following keys:\n",
    "\n",
    "- `messages` stores all messages to and from our LLM. *Notice:* we need a reducer function to integrate the update to the state sent by nodes.\n",
    "\n",
    "- `documents_to_chat`: stores the document we want to chat with, that is used as an index for the embedded chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class RAGState(TypedDict):\n",
    "    \"\"\"Main state for the RAG system\"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    documents_to_chat: List[str]  # Selected document keys (doc_keys)\n",
    "\n",
    "# TODO: Build the graph for this state. \n",
    "design_graph = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3b7f9",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60ca10",
   "metadata": {},
   "source": [
    "#### Tool 1: embed YouTube-transcript or PDF\n",
    "\n",
    "We add chunks of YouTube-transcripts or PDF documents in our vector database for later retrieval by providing a file path for a PDF or a link to a Youtube video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "328864e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def embed_document(source: str, doc_type: Literal[\"youtube\", \"pdf\"]) -> str:\n",
    "    \"\"\"Embed (or update) a YouTube video or PDF into the vector store.\n",
    "\n",
    "    Uses deterministic per-chunk IDs derived from a document key so re-embedding\n",
    "    replaces the prior version cleanly. Applies an atomic metadata update to\n",
    "    avoid lost updates when multiple embeddings run concurrently.\n",
    "\n",
    "    Args:\n",
    "        source: For PDFs a local file path. For YouTube a full video URL.\n",
    "        doc_type: The type of document to embed. Must be either \"youtube\" or \"pdf\".\n",
    "\n",
    "    Returns:\n",
    "        A human-readable summary including document key and number of chunks embedded.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build documents & add to vector store first (idempotent aside from deletes)\n",
    "        metadata_snapshot = load_metadata(METADATA_FILE)\n",
    "        doc_info = get_documents(source, doc_type)\n",
    "        doc_info, chunks = embed_documents(doc_info, text_splitter, vector_store, metadata_snapshot, doc_type)\n",
    "        (_, title, uploader, doc_key) = doc_info\n",
    "\n",
    "        from chat_with_X_utils.metadata_mangement import atomic_update_metadata\n",
    "\n",
    "        def _apply(current_meta):\n",
    "            current_meta = dict(current_meta)\n",
    "            current_meta[doc_key] = {\n",
    "                'title': title,\n",
    "                'type': doc_type,\n",
    "                'source': source,\n",
    "                'embedded_at': datetime.now().isoformat(),\n",
    "                'num_chunks': len(chunks)\n",
    "            }\n",
    "            if doc_type == 'youtube':\n",
    "                current_meta[doc_key]['uploader'] = uploader\n",
    "            return current_meta, current_meta[doc_key]\n",
    "\n",
    "        atomic_update_metadata(METADATA_FILE, _apply)\n",
    "        return f\"Embedded/Updated {doc_type}: '{title}' ({len(chunks)} chunks) key={doc_key}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error embedding document: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e532d4",
   "metadata": {},
   "source": [
    "#### Tool 2: list documents available in database\n",
    "\n",
    "Here we list which documents are currently available from our vector database by retrieving the information from our metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae8367ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def list_documents() -> str:\n",
    "    \"\"\"List stored documents (sorted by title) with basic stats.\n",
    "\n",
    "    Returns:\n",
    "        Multi-line string enumerating each document, its key, chunk count and date.\n",
    "    \"\"\"\n",
    "    metadata = load_metadata(METADATA_FILE)\n",
    "    if not metadata:\n",
    "        return \"No documents in the database.\"\n",
    "    return get_database_info(metadata) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34303a3",
   "metadata": {},
   "source": [
    "#### Tool 3: select which available document we want to chat with. \n",
    "\n",
    "For this we need to alter the graphs state from within the tool using the [Command](https://langchain-ai.github.io/langgraph/concepts/low_level/#command) object. \n",
    "\n",
    "\n",
    "- Because of the Message API we also need to append a ToolMessage with the correct ToolCallID to the `messages` key in the state. \n",
    "\n",
    "- For this we need to inject the `ToolCallId` tool call using [`InjectedToolCallId`](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.InjectedToolCallId.html). Note that this usually gets handled automatically when returning a regular String/ToolMessage from the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46bb176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def select_documents_for_chat(\n",
    "    doc_keys: List[str],\n",
    "    # TODO: Inject the tool call ID so you can attach a ToolMessage with the right ID\n",
    "    tool_call_id: ... = \"\",  \n",
    "):\n",
    "    \"\"\"Select documents (by key) to constrain subsequent retrieval.\n",
    "\n",
    "    Args:\n",
    "        doc_keys: List of document keys to select.\n",
    "        tool_call_id: (Injected) Tool call ID used to attach a ToolMessage.\n",
    "\n",
    "    Returns:\n",
    "        Command updating state.documents_to_chat plus a summary ToolMessage.\n",
    "    \"\"\"\n",
    "    metadata = load_metadata(METADATA_FILE)\n",
    "    summary, valid_documents = create_selection_summary(metadata, doc_keys)\n",
    "    # TODO: Return a Command that updates documents_to_chat and appends a ToolMessage with the summary and correct tool_call_id\n",
    "    return Command(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda27785",
   "metadata": {},
   "source": [
    "#### Tool 4: retrieve embedded document chunks\n",
    "\n",
    "- We want to limit the retrieval to specific documents, so we need to pass the corresponding value of the `documents_to_chat_with` key directly into the tool call using [`InjectedState`](https://langchain-ai.github.io/langgraph/reference/agents/?h=injectedstate#langgraph.prebuilt.tool_node.InjectedState).\n",
    "\n",
    "- This bypasses the possibility for the LLM-agent to make an error here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import InjectedState\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def retrieve_chunks(\n",
    "    query: str,\n",
    "    # TODO: Inject the select documents (documents_to_chat) from the state directly.\n",
    "    selected_documents: ... = [],\n",
    "    k: int = 5,\n",
    ") -> str:\n",
    "    \"\"\"Retrieve top-k chunks relevant to query over selected documents.\n",
    "\n",
    "    Args:\n",
    "        query: Natural language query to search for.\n",
    "        selected_documents: (Injected) List of doc_keys currently selected; empty means search all.\n",
    "        k: Number of chunks to return (default 5).\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with retrieved chunk excerpts and source citations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filter_dict = {\"doc_key\": {\"$in\": selected_documents}} if selected_documents else None\n",
    "        results = vector_store.similarity_search(query=query, k=k, filter=filter_dict)\n",
    "    \n",
    "        if not results:\n",
    "            return \"No relevant chunks found.\"\n",
    "    \n",
    "        return parse_retrieval(results) \n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving chunks: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499c12a",
   "metadata": {},
   "source": [
    "#### Tool 5: delete documents\n",
    "\n",
    "Let's now combine everything we've learned about handling the graph state using injections and the Command object, by writing a tool to\n",
    "\n",
    "- delete documents from our vector store and metadata file\n",
    "\n",
    "- while automatically deselecting them from the `documents_to_chat` key in our state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc32a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import InjectedState\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def delete_documents(\n",
    "    doc_keys: List[str],\n",
    "    # TODO: Inject the current selection (documents_to_chat) from the state directly.\n",
    "    current_selection: ... = [],\n",
    "    # TODO: Inject the tool call ID so you can attach a ToolMessage with the right ID\n",
    "    tool_call_id: ... = \"\",\n",
    "):\n",
    "    \"\"\"Delete one or more documents and prune them from current selection atomically.\n",
    "\n",
    "    Args:\n",
    "        doc_keys: List of document keys to delete (supports multiple at once).\n",
    "        current_selection: (Injected) Current selected doc keys from state.documents_to_chat.\n",
    "        tool_call_id: (Injected) Tool call ID used to attach a ToolMessage.\n",
    "\n",
    "    Returns:\n",
    "        Command that updates documents_to_chat and appends a deletion summary ToolMessage.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from chat_with_X_utils.metadata_mangement import atomic_update_metadata, load_metadata\n",
    "        from chat_with_X_utils.tool_utils import delete_documents_from_store, create_deletion_summary\n",
    "\n",
    "        # Perform metadata mutation under atomic lock so parallel deletions don't race.\n",
    "        def _apply(current_meta):\n",
    "            # delete_documents_from_store mutates metadata in-place and returns summary info\n",
    "            info = delete_documents_from_store(current_meta, doc_keys, vector_store)\n",
    "            return current_meta, info  # updated dict + info tuple\n",
    "\n",
    "        info = atomic_update_metadata(METADATA_FILE, _apply)\n",
    "        # info = (not_found, deleted_keys, deleted_title_pairs)\n",
    "        summary, updated_selection = create_deletion_summary(info, current_selection)\n",
    "\n",
    "        # TODO: Return a Command that updates documents_to_chat and appends a ToolMessage with the summary and correct tool_call_id\n",
    "        return Command(...)\n",
    "    except Exception as e:\n",
    "        return f\"Error deleting document(s): {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1542207",
   "metadata": {},
   "source": [
    "### Nodes: Chat-LLM + tools\n",
    "\n",
    "- **Before:** we only use one LLM-based node as our assistant. \n",
    "\n",
    "- **Now:** we put the `delete_documents` tool into a separate node $\\rightarrow$ we want to interrupt the graph's execution and wait for user confirmation as a guard-rail against LLM-induced errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for chat node (moved out of the node function)\n",
    "TOOLS_ALL = [\n",
    "    embed_document,\n",
    "    list_documents,\n",
    "    select_documents_for_chat,\n",
    "    retrieve_chunks,\n",
    "    delete_documents,\n",
    "]\n",
    "\n",
    "# TODO: Define SAFE_TOOLS and SENSITIVE_TOOLS appropriately.\n",
    "SAFE_TOOLS = [...]\n",
    "SENSITIVE_TOOLS = [...]\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful RAG assistant. Use tools for document management and retrieval. \"\n",
    "    \"Always call retrieve_chunks(query=..., k=...) before giving a substantive answer that relies on document content. \"\n",
    "    \"Cite timestamps for YouTube (mm:ss) and page numbers for PDFs when possible. \"\n",
    "    \"If information isn't found, say so explicitly.\"\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(TOOLS_ALL)\n",
    "\n",
    "WELCOME_MESSAGE = (\n",
    "    \"Welcome to the RAG System! I can help you:\\n\\n\"\n",
    "    \"ðŸ“š Document Management:\\n\"\n",
    "    \"- Embed (or update) YouTube videos or PDFs\\n\"\n",
    "    \"- List stored documents (shows each document key)\\n\"\n",
    "    \"- Delete documents by key (will ask for confirmation)\\n\\n\"\n",
    "    \"ðŸ’¬ Chat & Retrieval:\\n\"\n",
    "    \"- Ask questions about your selected documents\\n\"\n",
    "    \"- Retrieve supporting chunks with sources (timestamps/pages)\\n\\n\"\n",
    "    \"Just tell me what you'd like to do!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970517f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7018c877bb30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat_node(state: RAGState) -> Dict:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    current_selection = state.get(\"documents_to_chat\", [])\n",
    "\n",
    "    # First turn: emit a welcome AIMessage without invoking the LLM \n",
    "    if not messages:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=WELCOME_MESSAGE)],\n",
    "            \"documents_to_chat\": current_selection\n",
    "        }\n",
    "\n",
    "    # Invoke the already tool-bound model with a prepended system message\n",
    "    response = llm_with_tools.invoke([\n",
    "        SystemMessage(content=SYSTEM_PROMPT),\n",
    "        *messages\n",
    "    ])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "design_graph.add_node(\"chat\", chat_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b809b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7018c877bb30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nodes containing tool execution logic (referencing pre-defined tool groups)\n",
    "design_graph.add_node(\"safe_tools\", ToolNode(SAFE_TOOLS))\n",
    "design_graph.add_node(\"sensitive_tools\", ToolNode(SENSITIVE_TOOLS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405b985",
   "metadata": {},
   "source": [
    "### Edges\n",
    "\n",
    "- **Before** our routing function routed every tool call to the \"tools\" node or END if there are no tool calls.\n",
    "\n",
    "- **Now** we want to route based on the safety of a tool we write a custom [conditional edge](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges), which returns the name of the node to route to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5bd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7018c877bb30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def route_tools(state: RAGState):\n",
    "    nxt = tools_condition(state)\n",
    "    if nxt == END:\n",
    "        return END\n",
    "    ai_msg = state[\"messages\"][-1]\n",
    "    sensitive = {getattr(t, \"name\", getattr(t, \"__name__\", \"\")) for t in (SENSITIVE_TOOLS or [])} or {\"delete_documents\"}\n",
    "    if any(tc.get(\"name\") in sensitive for tc in getattr(ai_msg, \"tool_calls\", [])):\n",
    "        return \"sensitive_tools\"\n",
    "    return \"safe_tools\"\n",
    "\n",
    "design_graph.add_edge(START, \"chat\")\n",
    "# TODO: Add conditional edges from chat to the tool nodes using route_tools\n",
    "design_graph...\n",
    "design_graph.add_edge(\"safe_tools\", \"chat\")\n",
    "design_graph.add_edge(\"sensitive_tools\", \"chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72153c9",
   "metadata": {},
   "source": [
    "### Compile and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8febca",
   "metadata": {},
   "source": [
    "- We only want to user sensitive tools with after getting a user confirmation (*human-in-the-loop*). \n",
    "\n",
    "- So, we use the `interrupt_before` argument in the [compile](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph.compile) function, that specifies the node before with the interrupt occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b902f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "compiled_graph = design_graph.compile(\n",
    "    checkpointer=memory,\n",
    "    # TODO: Make the graph interrupt before calling sensitive tools\n",
    "    ...,\n",
    ")\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(compiled_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"Mermaid rendering failed, trying ascii art\")\n",
    "    print(compiled_graph.get_graph().print_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a04b9b",
   "metadata": {},
   "source": [
    "### Putting user in the graph stream \n",
    "\n",
    "- If the graph's execution is interrupted, it's state will have the `next` parameter set to the name of the node the execution should continue on, once we invoke the graph again.\n",
    "\n",
    "- During the interrupt, we ask for the user's approval for delete calls. If user says\n",
    "    - **yes (y):** we just need to continue the graph's execution\n",
    "    - **no (n):** we still need to append a `ToolMessage` with the correct tool_call_id to the `messages` key to satisfy the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a550b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Welcome to the RAG System! I can help you:\n",
      "\n",
      "ðŸ“š Document Management:\n",
      "- Embed (or update) YouTube videos or PDFs\n",
      "- List stored documents (shows each document key)\n",
      "- Delete documents by key (will ask for confirmation)\n",
      "\n",
      "ðŸ’¬ Chat & Retrieval:\n",
      "- Ask questions about your selected documents\n",
      "- Retrieve supporting chunks with sources (timestamps/pages)\n",
      "\n",
      "Just tell me what you'd like to do!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, what's embedded? Retrieve some random chunk aboiut the stuff please\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, what's embedded? Retrieve some random chunk aboiut the stuff please\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  list_documents (call_yfUZDYhDdZvwtaZv9TCbZpi1)\n",
      " Call ID: call_yfUZDYhDdZvwtaZv9TCbZpi1\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: list_documents\n",
      "\n",
      "Documents in database:\n",
      "\n",
      "ðŸ“„ Singular_Value_Decomposition_Tutorial\n",
      "   key: Singular_Value_Decomposition_Tutorial | chunks: 49 | added: 2025-09-06\n",
      "Call ID: call_yfUZDYhDdZvwtaZv9TCbZpi1\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  list_documents (call_yfUZDYhDdZvwtaZv9TCbZpi1)\n",
      " Call ID: call_yfUZDYhDdZvwtaZv9TCbZpi1\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: list_documents\n",
      "\n",
      "Documents in database:\n",
      "\n",
      "ðŸ“„ Singular_Value_Decomposition_Tutorial\n",
      "   key: Singular_Value_Decomposition_Tutorial | chunks: 49 | added: 2025-09-06\n",
      "Call ID: call_yfUZDYhDdZvwtaZv9TCbZpi1\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  select_documents_for_chat (call_8qpqZUdGagGDtGvrMZbnPfHb)\n",
      " Call ID: call_8qpqZUdGagGDtGvrMZbnPfHb\n",
      "  Args:\n",
      "    doc_keys: ['Singular_Value_Decomposition_Tutorial']\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: select_documents_for_chat\n",
      "\n",
      "Selected for chat: Singular_Value_Decomposition_Tutorial\n",
      "Call ID: call_8qpqZUdGagGDtGvrMZbnPfHb\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  select_documents_for_chat (call_8qpqZUdGagGDtGvrMZbnPfHb)\n",
      " Call ID: call_8qpqZUdGagGDtGvrMZbnPfHb\n",
      "  Args:\n",
      "    doc_keys: ['Singular_Value_Decomposition_Tutorial']\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: select_documents_for_chat\n",
      "\n",
      "Selected for chat: Singular_Value_Decomposition_Tutorial\n",
      "Call ID: call_8qpqZUdGagGDtGvrMZbnPfHb\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_chunks (call_JitOK3k9XSMjxsd2IQNhQS76)\n",
      " Call ID: call_JitOK3k9XSMjxsd2IQNhQS76\n",
      "  Args:\n",
      "    query: random\n",
      "    k: 1\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_chunks (call_JitOK3k9XSMjxsd2IQNhQS76)\n",
      " Call ID: call_JitOK3k9XSMjxsd2IQNhQS76\n",
      "  Args:\n",
      "    query: random\n",
      "    k: 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_chunks\n",
      "\n",
      "Retrieved 1 chunk(s):\n",
      "\n",
      "--- Chunk 1 (PDF: Singular_Value_Decomposition_Tutorial p2) ---\n",
      "ROUGH DRAFT - USE AT OWN RISK: suggestions kbaker@ling.osu.edu There are Â¯ve categories, so we're dealing with points in 5-space. Thus, the interpretation of the point (3;18;2;0:5;1;) would be \\three eggs, eighteen grapes, two bananas, half a chicken, one can of tuna\". 3 Vectors For most purposes, points and vectors are essentially the same thing1, that is, a sequence of numbers corresponding to measurements along various dimensions. Vectors are usually denoted by a lower case letter with an arrow on top, e.g. ~x. The numbers comprising the vector are now called components, and the number of components equals the dimensionality of the vector. We use a subscript on the vector name to refer to the component in that position. In the example below, ~x is a 5-dimensional vector, x1 = 8, x2 = 5, etc. ~x = 0 B B B B B B @ 8 6 7 5 3 1 C C C C C C A Vectors can be equivalently represented horizontally to save space, e.g. ~x = [8;6;7;5;3] is\n",
      "Call ID: call_JitOK3k9XSMjxsd2IQNhQS76\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_chunks\n",
      "\n",
      "Retrieved 1 chunk(s):\n",
      "\n",
      "--- Chunk 1 (PDF: Singular_Value_Decomposition_Tutorial p2) ---\n",
      "ROUGH DRAFT - USE AT OWN RISK: suggestions kbaker@ling.osu.edu There are Â¯ve categories, so we're dealing with points in 5-space. Thus, the interpretation of the point (3;18;2;0:5;1;) would be \\three eggs, eighteen grapes, two bananas, half a chicken, one can of tuna\". 3 Vectors For most purposes, points and vectors are essentially the same thing1, that is, a sequence of numbers corresponding to measurements along various dimensions. Vectors are usually denoted by a lower case letter with an arrow on top, e.g. ~x. The numbers comprising the vector are now called components, and the number of components equals the dimensionality of the vector. We use a subscript on the vector name to refer to the component in that position. In the example below, ~x is a 5-dimensional vector, x1 = 8, x2 = 5, etc. ~x = 0 B B B B B B @ 8 6 7 5 3 1 C C C C C C A Vectors can be equivalently represented horizontally to save space, e.g. ~x = [8;6;7;5;3] is\n",
      "Call ID: call_JitOK3k9XSMjxsd2IQNhQS76\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I found a chunk from the document \"Singular_Value_Decomposition_Tutorial\" about vectors in 5-dimensional space. It explains that points and vectors are essentially the same, representing sequences of numbers corresponding to measurements along various dimensions. For example, a 5-dimensional vector x can be written as x = [8;6;7;5;3], where each number is a component of the vector (page 2).\n",
      "\n",
      "If you'd like more details or chunks on a specific topic, just let me know!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I found a chunk from the document \"Singular_Value_Decomposition_Tutorial\" about vectors in 5-dimensional space. It explains that points and vectors are essentially the same, representing sequences of numbers corresponding to measurements along various dimensions. For example, a 5-dimensional vector x can be written as x = [8;6;7;5;3], where each number is a component of the vector (page 2).\n",
      "\n",
      "If you'd like more details or chunks on a specific topic, just let me know!\n",
      "Goodbye!\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "def stream_graph_updates_with_interrupt(graph, user_input: str, config: dict, _printed: set):\n",
    "    for event in graph.stream({\"messages\": [HumanMessage(content=user_input)]},\n",
    "                              config, \n",
    "                              stream_mode=\"values\"):\n",
    "        _print_messages_from_stream_event(event, _printed)\n",
    "    # After streaming, check for interrupt (pending sensitive tool execution)\n",
    "    snapshot = graph.get_state(config)\n",
    "    # TODO: Make sure the loop conditions gets triggered if the graph is interrupted\n",
    "    while ...:  \n",
    "        # Ask user approval\n",
    "        try:\n",
    "            decision = input(\"Approve deletion tool call? ('y' to continue / or reason to deny): \")\n",
    "        except Exception:\n",
    "            decision = \"y\"\n",
    "        if decision.strip().lower() == \"y\":\n",
    "            # Continue execution (execute the sensitive tool)\n",
    "            result = graph.invoke(None, config)\n",
    "            _print_messages_from_state(result, _printed)\n",
    "        else:\n",
    "            # Deny: send ToolMessage with denial so model can adjust\n",
    "            last_message = snapshot.values[\"messages\"][-1]\n",
    "            tool_call_id = last_message.tool_calls[0][\"id\"]\n",
    "            # TODO: Invoke the graph with a new message in the graph state while satisfying the tool call ID requirement\n",
    "            denial = graph.invoke({\n",
    "                \"messages\": [\n",
    "                    ToolMessage(\n",
    "                        tool_call_id=...\n",
    "                        ,\n",
    "                        content=f\"Deletion denied by user. Reasoning: {decision} Continue without deleting and assist further.\"\n",
    "                    )\n",
    "                ]\n",
    "            }, config)\n",
    "            _print_messages_from_state(denial, _printed)\n",
    "        snapshot = graph.get_state(config)\n",
    "\n",
    "\n",
    "# Configure a new thread/session\n",
    "config = {\"configurable\": {\"thread_id\": \"rag_session_1\"}}\n",
    "\n",
    "# Track printed message ids to avoid duplicates on stream\n",
    "_printed = set()\n",
    "\n",
    "welcome_result = compiled_graph.invoke({\"messages\": [], \"documents_to_chat\": []}, config)\n",
    "_print_messages_from_state(welcome_result, _printed)\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    user_input = input(\"\\nUser: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    stream_graph_updates_with_interrupt(compiled_graph, user_input, config, _printed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
